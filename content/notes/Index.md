---
longform:
  format: scenes
  title: notes
  workflow: Default Workflow
  sceneFolder: /
  scenes:
    - Auto regressive decoding
    - Residual Connection
    - Layer Norm
    - Batch Norm
    - RNN
    - GPUs and Other Accelerators
    - Transformer
    - Large Language Model
    - Relative Positional Encoding
    - KV cache
    - Gated Linear Unit (GLU)
    - Multi-Query Attention
    - Group-Query Attention
    - LLaMA
    - Attention with Linear Biases (ALiBi)
    - Rotary Position Embeddings (RoPE)
    - Euler's Formula
  sceneTemplate: templates/Chapter.md
  ignoredFiles:
    - normalization methods
draft: false
---
